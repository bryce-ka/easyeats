{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00299fad-ce91-40c6-b999-b3b3afdff072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# proxy stuff- may not get used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe80998-8baf-4cc2-b88f-62d8fb6771a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests, re\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "regex = r\"[0-9]+(?:\\.[0-9]+){3}:[0-9]+\"\n",
    "c = requests.get(\"https://spys.me/proxy.txt\")\n",
    "test_str = c.text\n",
    "a = re.finditer(regex, test_str, re.MULTILINE)\n",
    "with open(\"proxies_list.txt\", 'w') as file:\n",
    "    for i in a:\n",
    "       print(i.group(),file=file)\n",
    "        \n",
    "d = requests.get(\"https://free-proxy-list.net/\")\n",
    "soup = BeautifulSoup(d.content, 'html.parser')\n",
    "td_elements = soup.select('.fpl-list .table tbody tr td')\n",
    "ips = []\n",
    "ports = []\n",
    "for j in range(0, len(td_elements), 8):\n",
    "    ips.append(td_elements[j].text.strip())\n",
    "    ports.append(td_elements[j + 1].text.strip())\n",
    "with open(\"proxies_list.txt\", \"a\") as myfile:\n",
    "    for ip, port in zip(ips, ports):\n",
    "        proxy = f\"{ip}:{port}\"\n",
    "        print(proxy, file=myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9bce427-3a23-4eb1-aaa5-39f809d257f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "proxies = []\n",
    "with open('proxies_list.txt') as file:\n",
    "    for proxy_line in file:\n",
    "        proxies.append(proxy_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9328e5-410a-41f7-b6d4-aded932d0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://ipecho.net/plain'\n",
    "working = 0\n",
    "with open('working_proxies.txt', 'w') as file:\n",
    "    for proxy in proxies:\n",
    "        try:\n",
    "            # https://ipecho.net/plain returns the ip address\n",
    "            # of the current session if a GET request is sent.\n",
    "            page = requests.get(\n",
    "              url, proxies={\"http\": proxy, \"https\": proxy}, timeout=5)\n",
    "            if page.status_code == 200:\n",
    "                file.write(proxy +'\\n')\n",
    "                working+=1\n",
    "        except requests.RequestException:  # Catch all request-related errors\n",
    "            continue\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "        print(f\"Working proxies found: {working}\")\n",
    "        time.sleep(0.1)  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642c72ef-b3f6-4dce-bcd4-c112f417fb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response_m.content, 'html.parser')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
